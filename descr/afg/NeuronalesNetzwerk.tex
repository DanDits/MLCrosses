\vspace{-1.5em}

Angekreuzt sein oder nicht angekreuzt sein, das ist hier die Frage. 
Wir stehen also vor einem \emph{binärem Klassifizierungsproblem}.\\
Für solche (und viele anderen) sind in den letzten Jahren die sogenannten \emph{Deep neural networks} immer beliebter geworden. Dieser Algorithmus schafft es, gefüttert mit bereits klassifizierten Daten, durch automatisches Lernen ein Modell zu finden.


Ziel ist es, eine eigene kleine Implementierung eines sehr flachen neuronalen Netzwerkes zu verwenden. 
Als \emph{Bonusaufgabe}(!) ist es ebenfalls möglich das Netzwerk tiefer und mächtiger zu machen, dies ist aber für unser Problem nicht nötig.\\

Im Folgenden ist die mathematische Beschreibung eines tiefen neuronalen Netzwerks gegeben. Für den einfachen flachen Fall gilt $s=1$.\\
Zu Eingabedaten $x\in \R^n$, $n_0=n$, $n_s=m$ und $a_0=x$ berechnen wir iterativ 
$$z_j=W_ja_{j-1} + b_j,\;a_j=\sigma_j(z_j),\;j=1,\dots,s$$
Dabei ist für $j=1,\dots,s$:
\begin{itemize}
 \item $W_j \in \R^{n_{j-1}\times n_j}$ die Gewichtsmatrix
 \item $b_j \in \R^{n_j}$ der Biasvektor
 \item $\sigma_j \colon \R^{n_j} \to [0,1]^{n_j}$ die vektorisierte Aktivierungsfunktion $\sigma \colon \R \to \R$ des Neurons
\end{itemize}
Diesen Vorgang $x$ iterativ durch das Netzwerk zu schicken wird \emph{feedforward} genannt. Man erhält dann die Vorhersage $a=a_s$ des Modells.\\

Ein Teil der zur Verfügung stehenden Daten (z.B. 75\%) verwendet man für das Training, den Rest zur Validierung des Modells.
Ziel ist es anhand von vielen bekannten Trainingsdaten $(x,y)\in \R^n \times \R^m$ die Gewichte $W_j$ und den Bias $b_j$ automatisch zu optimieren.\\
Daher benötigen wir eine zu optimierende Kostenfunktion $c\colon \R^m \to \R_{\ge 0}$, die stetig differenzierbar ist. Wir führen ein Gradientenabstiegsverfahren durch, wobei wir jeweils für $k$ Bilder (=einen Batch) einen Schritt mit Schrittweite (=Lernrate) $\eta$ in Richtung des negativen Gradienten $\frac{\partial c}{\partial b}$ und $\frac{\partial c}{\partial W}$ machen.\\\\
\underline{Algorithmus für $s=1$}:
\begin{enumerate}
 \item Initialisiere Gewichtsmatrix $W$ und Biasvektor $b$ mit $\mathcal{N}(0,1)$ verteilten Werten. Teile die Gewichte zusätzlich durch $\sqrt{n}$.
 \item Eingabedaten $x\in\R^n$ sind die auf $[0,1]$ normalisierten Grauwerte der Pixel des Kästchenbildes.
 \item Für einige Wiederholungen (=Epochen) zerlege Trainingsdaten zufällig in Batches $B$ der Größe $k$. Für jeden Batch berechne und summiere die Gradienten für jedes Datum und update anschließend \\
 $b \mathrel{-}= (\frac{\eta}{k})\;\sum_{x\in B}\frac{\partial c}{\partial z}$ und 
 $W \mathrel{-}= (\frac{\eta}{k})\;\sum_{x\in B}\frac{\partial c}{\partial z} \cdot x^T$\
\item Die Ausgabe $a\in\R^2$ kodiert die gesuchte Information. Dabei ist für bekannte Daten der Vektor $(1,0)^T$ ein leeres und $(0,1)^T$ ein angekreuztes Kästchen. Für unbekannte Daten ist der größere der beiden Einträge ausschlaggebend.
\end{enumerate}
\\
\underline{Praktische und konkrete Funktionen}\\
Viele Aktivierungsfunktionen und Kostenfunktionen sind möglich (Bonus: Implementierung flexibel halten!), ein funktionierender Vorschlag:
\begin{align*}
z&=b+Wx\\
\sigma(z)&=\frac{1}{1+e^{-z}}, \text{ (Sigmoid Aktivierungsfunktion)}\\
a&=\sigma(z)\\
c(a,y)&=\sum_{i=1}^m -y_i\log(a_i) -(1-y_i)\log(1-a_i), \text{ (Cross-Entropy-Cost)}\\
\frac{\partial c}{\partial z}(\sigma(z),y)&=(\sigma(z) - y)\frac{\sigma^\prime(z)}{\sigma(z)(1-\sigma(z)}\\
k&=50\\
epochen&=30+\\
\eta&=0.1
\end{align*}